{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":9102,"status":"ok","timestamp":1718699504658,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"},"user_tz":-120},"id":"AhbFCiyyjPjc","outputId":"8d3a5239-a3be-401c-93c2-a08e18533f4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary size (words): len(y[i]): 3397\n","Total X variables: 163223\n","\n","Text train example1\n"]},{"output_type":"display_data","data":{"text/plain":["'20015kt 9999 prec0y CL2 CM5 18 15 q1013 19010KT 9999 FEW030 19/16 Q1015 NOSIG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 1\n"]},{"output_type":"display_data","data":{"text/plain":["[261, 1, 20, 45, 76, 18, 9, 43, 675, 1, 54, 28, 12, 32, 4]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Text train example2\n"]},{"output_type":"display_data","data":{"text/plain":["'16009kt 9999 prec0n CL0 CM3 22 16 q1012 12009KT 9999 -RA NSC 21/15 Q1011 TEMPO TSRA SCT040CB'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 2\n"]},{"output_type":"display_data","data":{"text/plain":["[520, 1, 2, 5, 80, 57, 12, 49, 1346, 1, 26, 71, 44, 9, 53, 17, 919, 1181]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","X\n"]},{"output_type":"display_data","data":{"text/plain":["array([[   0,    0,    0,    0,    0,  261,    1,   20,   45,   76,   18,\n","           9,   43],\n","       [   0,    0,    0,    0,  261,    1,   20,   45,   76,   18,    9,\n","          43,  675],\n","       [   0,    0,    0,  261,    1,   20,   45,   76,   18,    9,   43,\n","         675,    1],\n","       [   0,    0,  261,    1,   20,   45,   76,   18,    9,   43,  675,\n","           1,   54],\n","       [   0,  261,    1,   20,   45,   76,   18,    9,   43,  675,    1,\n","          54,   28],\n","       [ 261,    1,   20,   45,   76,   18,    9,   43,  675,    1,   54,\n","          28,   12],\n","       [   1,   20,   45,   76,   18,    9,   43,  675,    1,   54,   28,\n","          12,   32],\n","       [   0,    0,    0,    0,    0,  520,    1,    2,    5,   80,   57,\n","          12,   49],\n","       [   0,    0,    0,    0,  520,    1,    2,    5,   80,   57,   12,\n","          49, 1346],\n","       [   0,    0,    0,  520,    1,    2,    5,   80,   57,   12,   49,\n","        1346,    1],\n","       [   0,    0,  520,    1,    2,    5,   80,   57,   12,   49, 1346,\n","           1,   26],\n","       [   0,  520,    1,    2,    5,   80,   57,   12,   49, 1346,    1,\n","          26,   71],\n","       [ 520,    1,    2,    5,   80,   57,   12,   49, 1346,    1,   26,\n","          71,   44],\n","       [   1,    2,    5,   80,   57,   12,   49, 1346,    1,   26,   71,\n","          44,    9],\n","       [   2,    5,   80,   57,   12,   49, 1346,    1,   26,   71,   44,\n","           9,   53],\n","       [   5,   80,   57,   12,   49, 1346,    1,   26,   71,   44,    9,\n","          53,   17],\n","       [  80,   57,   12,   49, 1346,    1,   26,   71,   44,    9,   53,\n","          17,  919],\n","       [   0,    0,    0,    0,    0,  261,    1,    2,    5,    3,   11,\n","          19,   25],\n","       [   0,    0,    0,    0,  261,    1,    2,    5,    3,   11,   19,\n","          25,  351],\n","       [   0,    0,    0,  261,    1,    2,    5,    3,   11,   19,   25,\n","         351,    1],\n","       [   0,    0,  261,    1,    2,    5,    3,   11,   19,   25,  351,\n","           1,  106],\n","       [   0,  261,    1,    2,    5,    3,   11,   19,   25,  351,    1,\n","         106,  135],\n","       [ 261,    1,    2,    5,    3,   11,   19,   25,  351,    1,  106,\n","         135,   16],\n","       [   1,    2,    5,    3,   11,   19,   25,  351,    1,  106,  135,\n","          16,   21],\n","       [   2,    5,    3,   11,   19,   25,  351,    1,  106,  135,   16,\n","          21,   25]], dtype=int32)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Dictionary first 10 words\n"]},{"output_type":"display_data","data":{"text/plain":["{'9999': 1,\n"," 'prec0n': 2,\n"," 'cm0': 3,\n"," 'nosig': 4,\n"," 'cl0': 5,\n"," '12': 6,\n"," '13': 7,\n"," '14': 8,\n"," '15': 9,\n"," '11': 10}"]},"metadata":{}}],"source":["#@title Get text train and test ,X and Y\n","nrows_train = 20000 # @param {type:\"integer\"}\n","sequence_length = 13 # @param {type:\"integer\"}\n","\n","feed_lenght = 8\n","\n","import pandas as pd\n","import numpy as np\n","import time\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import LSTM, Dense, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import Adam\n","import json\n","from keras.preprocessing.text import tokenizer_from_json\n","\n","#load fusion\n","fus = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LECO/LECOfusion1.csv\",\n","                  parse_dates=[\"time\"], index_col=\"time\")\n","\n","#Get the train and test train\n","texts_train = fus[\"fusion\"].sample(nrows_train,)\n","texts_test = fus[\"fusion\"].drop(texts_train.index)\n","\n","#save texts test\n","texts_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LECO/LECOtexts_test1.csv\")\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","\n","#tokenizer.fit_on_texts(texts_train)\n","tokenizer.fit_on_texts(fus[\"fusion\"])\n","\n","#Save tokenizer\n","tokenizer_json = tokenizer.to_json()\n","\n","# Save the JSON configuration to a file\n","with open('/content/drive/MyDrive/Colab Notebooks/gpt/LECO/LECOtokenizer_config1.json', 'w', encoding='utf-8') as f:\n","    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n","\n","sequences = tokenizer.texts_to_sequences(texts_train)\n","\n","# Prepare input and output data\n","X = []\n","y = []\n","for sequence in sequences:\n","    for i in range(1, len(sequence)):\n","        x_seq = sequence[:i]\n","        x_seq_padded = pad_sequences([x_seq], maxlen=sequence_length, padding='pre')\n","        X.append(x_seq_padded[0])\n","        y.append(sequence[i])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","#filter seed/model words\n","df = pd.DataFrame(X)\n","df[\"y\"] = y\n","df_fil =  df[(df.iloc[:, :sequence_length-feed_lenght+1] != 0).any(axis=1)]\n","X = df_fil.iloc[:, :-1].values\n","y = df_fil.iloc[:, -1].values\n","\n","# One hot encode the outputs\n","y = np.eye(len(tokenizer.word_index) + 1)[y]\n","\n","print(\"Dictionary size (words): len(y[i]):\",len(y[1]) )\n","print(\"Total X variables:\",len(X) )\n","\n","print(\"\\nText train example1\")\n","display(texts_train[0])\n","\n","print(\"\\nSequences example 1\")\n","display(sequences[0])\n","\n","print(\"\\nText train example2\")\n","display(texts_train[1])\n","\n","print(\"\\nSequences example 2\")\n","display(sequences[1])\n","\n","print(\"\\nX\")\n","display(X[:25])\n","\n","print(\"\\nDictionary first 10 words\")\n","display({k: tokenizer.word_index[k] for k in list(tokenizer.word_index)[:10]})\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fOX-9Am0V_d","executionInfo":{"status":"ok","timestamp":1718700637528,"user_tz":-120,"elapsed":1109328,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"}},"outputId":"17ebac14-55c4-4813-beee-4a0753a493c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","319/319 [==============================] - 25s 69ms/step - loss: 4.0193 - accuracy: 0.1977\n","Epoch 2/50\n","319/319 [==============================] - 22s 68ms/step - loss: 2.9292 - accuracy: 0.2807\n","Epoch 3/50\n","319/319 [==============================] - 22s 68ms/step - loss: 2.6271 - accuracy: 0.3198\n","Epoch 4/50\n","319/319 [==============================] - 22s 69ms/step - loss: 2.4860 - accuracy: 0.3383\n","Epoch 5/50\n","319/319 [==============================] - 22s 70ms/step - loss: 2.3960 - accuracy: 0.3521\n","Epoch 6/50\n","319/319 [==============================] - 22s 68ms/step - loss: 2.3279 - accuracy: 0.3625\n","Epoch 7/50\n","319/319 [==============================] - 22s 68ms/step - loss: 2.2710 - accuracy: 0.3728\n","Epoch 8/50\n","319/319 [==============================] - 22s 69ms/step - loss: 2.2157 - accuracy: 0.3809\n","Epoch 9/50\n","319/319 [==============================] - 22s 69ms/step - loss: 2.1702 - accuracy: 0.3893\n","Epoch 10/50\n","319/319 [==============================] - 22s 68ms/step - loss: 2.1150 - accuracy: 0.3999\n","Epoch 11/50\n","319/319 [==============================] - 22s 68ms/step - loss: 2.0663 - accuracy: 0.4094\n","Epoch 12/50\n","319/319 [==============================] - 22s 69ms/step - loss: 2.0172 - accuracy: 0.4200\n","Epoch 13/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.9685 - accuracy: 0.4300\n","Epoch 14/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.9236 - accuracy: 0.4398\n","Epoch 15/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.8818 - accuracy: 0.4502\n","Epoch 16/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.8424 - accuracy: 0.4607\n","Epoch 17/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.8030 - accuracy: 0.4692\n","Epoch 18/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.7719 - accuracy: 0.4750\n","Epoch 19/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.7343 - accuracy: 0.4863\n","Epoch 20/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.7038 - accuracy: 0.4936\n","Epoch 21/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.6806 - accuracy: 0.4986\n","Epoch 22/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.6640 - accuracy: 0.5023\n","Epoch 23/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.6380 - accuracy: 0.5087\n","Epoch 24/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.6094 - accuracy: 0.5154\n","Epoch 25/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.5893 - accuracy: 0.5193\n","Epoch 26/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.5735 - accuracy: 0.5231\n","Epoch 27/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.5393 - accuracy: 0.5324\n","Epoch 28/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.5208 - accuracy: 0.5379\n","Epoch 29/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.5094 - accuracy: 0.5394\n","Epoch 30/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.4879 - accuracy: 0.5450\n","Epoch 31/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.4738 - accuracy: 0.5482\n","Epoch 32/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.4628 - accuracy: 0.5507\n","Epoch 33/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.4602 - accuracy: 0.5502\n","Epoch 34/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.4528 - accuracy: 0.5531\n","Epoch 35/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.4436 - accuracy: 0.5542\n","Epoch 36/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.4792 - accuracy: 0.5428\n","Epoch 37/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.4615 - accuracy: 0.5474\n","Epoch 38/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.4231 - accuracy: 0.5585\n","Epoch 39/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.3980 - accuracy: 0.5656\n","Epoch 40/50\n","319/319 [==============================] - 22s 70ms/step - loss: 1.4001 - accuracy: 0.5657\n","Epoch 41/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.3810 - accuracy: 0.5706\n","Epoch 42/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.3705 - accuracy: 0.5717\n","Epoch 43/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.3704 - accuracy: 0.5732\n","Epoch 44/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.3808 - accuracy: 0.5694\n","Epoch 45/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.3759 - accuracy: 0.5686\n","Epoch 46/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.3837 - accuracy: 0.5676\n","Epoch 47/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.3612 - accuracy: 0.5727\n","Epoch 48/50\n","319/319 [==============================] - 22s 68ms/step - loss: 1.3512 - accuracy: 0.5763\n","Epoch 49/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.3422 - accuracy: 0.5773\n","Epoch 50/50\n","319/319 [==============================] - 22s 69ms/step - loss: 1.3960 - accuracy: 0.5615\n"]}],"source":["#@title Train the model\n","\n","from keras.layers import Bidirectional\n","\n","# Build the LSTM model\n","model = Sequential([\n","    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=20, input_length=sequence_length),\n","    Bidirectional(LSTM(130)),\n","\n","    Dense(len(tokenizer.word_index)+1, activation='softmax')\n","])\n","\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X, y, epochs=50,batch_size=512)\n","\n","#save the model\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/gpt/LECO/LECOmodel1.keras\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[{"file_id":"1PKiCntrB2pBLVWZRaL6x-uJpEvPlNmAg","timestamp":1717661221746},{"file_id":"1qsxpGdTrTbO4obEJ4QwGeDJUpuX7gXoW","timestamp":1717492644174},{"file_id":"1LGw-aME2JOnpzAyMOVamYWUAywgSV5mI","timestamp":1715852482288},{"file_id":"1_9maObId68xlnKd6JjYqJUMRMI14ASnx","timestamp":1715845357828},{"file_id":"1BterrhINI5z4G_D4Ntuk7p8a0iuZu7ql","timestamp":1714808806688},{"file_id":"1sqdm_O_jJnvjiOLxkCsuGODjv7CDiB0l","timestamp":1714549345450},{"file_id":"1GD83k4KMSFWH42Th2LjdPwK-hN39h8RT","timestamp":1713425984380}],"mount_file_id":"1pzApbE_cDl7-VW_M5jLFcfhHDeBUBrdE","authorship_tag":"ABX9TyNZQ8BmuluAFd3qlJJsAxye"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}