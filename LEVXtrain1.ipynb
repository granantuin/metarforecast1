{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6327,"status":"ok","timestamp":1718698186236,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"},"user_tz":-120},"id":"AhbFCiyyjPjc","outputId":"e75e641d-c189-4de3-9808-26ce97e86988"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary size (words): len(y[i]): 3026\n","Total X variables: 176072\n","\n","Text train example1\n"]},{"output_type":"display_data","data":{"text/plain":["'19005kt 9999 prec0n CL5 CM2 13 12 q1017 20008KT 170V230 3000 BR SCT003 BKN006 13/13 Q1016 TEMPO 0800 FG VV001'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 1\n"]},{"output_type":"display_data","data":{"text/plain":["[151,\n"," 1,\n"," 2,\n"," 41,\n"," 70,\n"," 9,\n"," 7,\n"," 22,\n"," 328,\n"," 144,\n"," 31,\n"," 53,\n"," 245,\n"," 240,\n"," 9,\n"," 9,\n"," 25,\n"," 16,\n"," 96,\n"," 45,\n"," 42]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Text train example2\n"]},{"output_type":"display_data","data":{"text/plain":["'00013kt 9999 prec0y CL5 CM7 14 11 q1025 01004KT 330V060 9999 SCT032 BKN049 13/13 Q1024 NOSIG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 2\n"]},{"output_type":"display_data","data":{"text/plain":["[621, 1, 32, 41, 158, 11, 8, 46, 427, 503, 1, 489, 575, 9, 9, 43, 4]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","X\n"]},{"output_type":"display_data","data":{"text/plain":["array([[  0,   0,   0,   0,   0, 151,   1,   2,  41,  70,   9,   7,  22],\n","       [  0,   0,   0,   0, 151,   1,   2,  41,  70,   9,   7,  22, 328],\n","       [  0,   0,   0, 151,   1,   2,  41,  70,   9,   7,  22, 328, 144],\n","       [  0,   0, 151,   1,   2,  41,  70,   9,   7,  22, 328, 144,  31],\n","       [  0, 151,   1,   2,  41,  70,   9,   7,  22, 328, 144,  31,  53],\n","       [151,   1,   2,  41,  70,   9,   7,  22, 328, 144,  31,  53, 245],\n","       [  1,   2,  41,  70,   9,   7,  22, 328, 144,  31,  53, 245, 240],\n","       [  2,  41,  70,   9,   7,  22, 328, 144,  31,  53, 245, 240,   9],\n","       [ 41,  70,   9,   7,  22, 328, 144,  31,  53, 245, 240,   9,   9],\n","       [ 70,   9,   7,  22, 328, 144,  31,  53, 245, 240,   9,   9,  25],\n","       [  9,   7,  22, 328, 144,  31,  53, 245, 240,   9,   9,  25,  16],\n","       [  7,  22, 328, 144,  31,  53, 245, 240,   9,   9,  25,  16,  96],\n","       [ 22, 328, 144,  31,  53, 245, 240,   9,   9,  25,  16,  96,  45],\n","       [  0,   0,   0,   0,   0, 621,   1,  32,  41, 158,  11,   8,  46],\n","       [  0,   0,   0,   0, 621,   1,  32,  41, 158,  11,   8,  46, 427],\n","       [  0,   0,   0, 621,   1,  32,  41, 158,  11,   8,  46, 427, 503],\n","       [  0,   0, 621,   1,  32,  41, 158,  11,   8,  46, 427, 503,   1],\n","       [  0, 621,   1,  32,  41, 158,  11,   8,  46, 427, 503,   1, 489],\n","       [621,   1,  32,  41, 158,  11,   8,  46, 427, 503,   1, 489, 575],\n","       [  1,  32,  41, 158,  11,   8,  46, 427, 503,   1, 489, 575,   9],\n","       [ 32,  41, 158,  11,   8,  46, 427, 503,   1, 489, 575,   9,   9],\n","       [ 41, 158,  11,   8,  46, 427, 503,   1, 489, 575,   9,   9,  43],\n","       [  0,   0,   0,   0,   0,  83,   1,   2,   5,   3,  58,  14,  23],\n","       [  0,   0,   0,   0,  83,   1,   2,   5,   3,  58,  14,  23, 785],\n","       [  0,   0,   0,  83,   1,   2,   5,   3,  58,  14,  23, 785, 852]],\n","      dtype=int32)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Dictionary first 10 words\n"]},{"output_type":"display_data","data":{"text/plain":["{'9999': 1,\n"," 'prec0n': 2,\n"," 'cm0': 3,\n"," 'nosig': 4,\n"," 'cl0': 5,\n"," 'cavok': 6,\n"," '12': 7,\n"," '11': 8,\n"," '13': 9,\n"," '10': 10}"]},"metadata":{}}],"source":["#@title Get text train and test ,X and Y\n","nrows_train = 20000 # @param {type:\"integer\"}\n","sequence_length = 13 # @param {type:\"integer\"}\n","\n","feed_lenght = 8\n","\n","import pandas as pd\n","import numpy as np\n","import time\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import LSTM, Dense, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import Adam\n","import json\n","from keras.preprocessing.text import tokenizer_from_json\n","\n","#load fusion\n","fus = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LEVX/LEVXfusion1.csv\",\n","                  parse_dates=[\"time\"], index_col=\"time\")\n","\n","#Get the train and test train\n","texts_train = fus[\"fusion\"].sample(nrows_train,)\n","texts_test = fus[\"fusion\"].drop(texts_train.index)\n","\n","#save texts test\n","texts_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LEVX/LEVXtexts_test1.csv\")\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","\n","#tokenizer.fit_on_texts(texts_train)\n","tokenizer.fit_on_texts(fus[\"fusion\"])\n","\n","#Save tokenizer\n","tokenizer_json = tokenizer.to_json()\n","\n","# Save the JSON configuration to a file\n","with open('/content/drive/MyDrive/Colab Notebooks/gpt/LEVX/LEVXtokenizer_config1.json', 'w', encoding='utf-8') as f:\n","    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n","\n","sequences = tokenizer.texts_to_sequences(texts_train)\n","\n","# Prepare input and output data\n","X = []\n","y = []\n","for sequence in sequences:\n","    for i in range(1, len(sequence)):\n","        x_seq = sequence[:i]\n","        x_seq_padded = pad_sequences([x_seq], maxlen=sequence_length, padding='pre')\n","        X.append(x_seq_padded[0])\n","        y.append(sequence[i])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","#filter seed/model words\n","df = pd.DataFrame(X)\n","df[\"y\"] = y\n","df_fil =  df[(df.iloc[:, :sequence_length-feed_lenght+1] != 0).any(axis=1)]\n","X = df_fil.iloc[:, :-1].values\n","y = df_fil.iloc[:, -1].values\n","\n","# One hot encode the outputs\n","y = np.eye(len(tokenizer.word_index) + 1)[y]\n","\n","print(\"Dictionary size (words): len(y[i]):\",len(y[1]) )\n","print(\"Total X variables:\",len(X) )\n","\n","print(\"\\nText train example1\")\n","display(texts_train[0])\n","\n","print(\"\\nSequences example 1\")\n","display(sequences[0])\n","\n","print(\"\\nText train example2\")\n","display(texts_train[1])\n","\n","print(\"\\nSequences example 2\")\n","display(sequences[1])\n","\n","print(\"\\nX\")\n","display(X[:25])\n","\n","print(\"\\nDictionary first 10 words\")\n","display({k: tokenizer.word_index[k] for k in list(tokenizer.word_index)[:10]})\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fOX-9Am0V_d","executionInfo":{"status":"ok","timestamp":1718699425354,"user_tz":-120,"elapsed":1169710,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"}},"outputId":"11c910ad-48a3-49ee-edc8-ccde2655f334"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","344/344 [==============================] - 26s 67ms/step - loss: 3.8154 - accuracy: 0.2225\n","Epoch 2/50\n","344/344 [==============================] - 23s 67ms/step - loss: 2.7691 - accuracy: 0.3146\n","Epoch 3/50\n","344/344 [==============================] - 23s 67ms/step - loss: 2.5139 - accuracy: 0.3421\n","Epoch 4/50\n","344/344 [==============================] - 23s 67ms/step - loss: 2.3821 - accuracy: 0.3608\n","Epoch 5/50\n","344/344 [==============================] - 23s 67ms/step - loss: 2.2986 - accuracy: 0.3735\n","Epoch 6/50\n","344/344 [==============================] - 23s 67ms/step - loss: 2.2363 - accuracy: 0.3833\n","Epoch 7/50\n","344/344 [==============================] - 23s 66ms/step - loss: 2.1811 - accuracy: 0.3913\n","Epoch 8/50\n","344/344 [==============================] - 23s 67ms/step - loss: 2.1274 - accuracy: 0.4015\n","Epoch 9/50\n","344/344 [==============================] - 23s 67ms/step - loss: 2.0722 - accuracy: 0.4099\n","Epoch 10/50\n","344/344 [==============================] - 23s 67ms/step - loss: 2.0200 - accuracy: 0.4201\n","Epoch 11/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.9660 - accuracy: 0.4306\n","Epoch 12/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.9151 - accuracy: 0.4428\n","Epoch 13/50\n","344/344 [==============================] - 24s 68ms/step - loss: 1.8649 - accuracy: 0.4542\n","Epoch 14/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.8174 - accuracy: 0.4635\n","Epoch 15/50\n","344/344 [==============================] - 23s 66ms/step - loss: 1.7750 - accuracy: 0.4743\n","Epoch 16/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.7362 - accuracy: 0.4814\n","Epoch 17/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.6925 - accuracy: 0.4921\n","Epoch 18/50\n","344/344 [==============================] - 23s 66ms/step - loss: 1.6608 - accuracy: 0.5005\n","Epoch 19/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.6291 - accuracy: 0.5091\n","Epoch 20/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.5992 - accuracy: 0.5152\n","Epoch 21/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.5710 - accuracy: 0.5213\n","Epoch 22/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.5433 - accuracy: 0.5286\n","Epoch 23/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.5225 - accuracy: 0.5338\n","Epoch 24/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.5004 - accuracy: 0.5396\n","Epoch 25/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.4824 - accuracy: 0.5444\n","Epoch 26/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.4609 - accuracy: 0.5493\n","Epoch 27/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.4425 - accuracy: 0.5542\n","Epoch 28/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.4317 - accuracy: 0.5567\n","Epoch 29/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.4231 - accuracy: 0.5572\n","Epoch 30/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.4028 - accuracy: 0.5618\n","Epoch 31/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3842 - accuracy: 0.5669\n","Epoch 32/50\n","344/344 [==============================] - 23s 66ms/step - loss: 1.3698 - accuracy: 0.5703\n","Epoch 33/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3626 - accuracy: 0.5729\n","Epoch 34/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3624 - accuracy: 0.5745\n","Epoch 35/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3496 - accuracy: 0.5773\n","Epoch 36/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3353 - accuracy: 0.5804\n","Epoch 37/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3343 - accuracy: 0.5793\n","Epoch 38/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3304 - accuracy: 0.5813\n","Epoch 39/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3187 - accuracy: 0.5852\n","Epoch 40/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3106 - accuracy: 0.5856\n","Epoch 41/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3143 - accuracy: 0.5849\n","Epoch 42/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3114 - accuracy: 0.5840\n","Epoch 43/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.3051 - accuracy: 0.5854\n","Epoch 44/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.2944 - accuracy: 0.5893\n","Epoch 45/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.2797 - accuracy: 0.5923\n","Epoch 46/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.2801 - accuracy: 0.5918\n","Epoch 47/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.2711 - accuracy: 0.5954\n","Epoch 48/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.2825 - accuracy: 0.5919\n","Epoch 49/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.2741 - accuracy: 0.5938\n","Epoch 50/50\n","344/344 [==============================] - 23s 67ms/step - loss: 1.2709 - accuracy: 0.5949\n"]}],"source":["#@title Train the model\n","\n","from keras.layers import Bidirectional\n","\n","# Build the LSTM model\n","model = Sequential([\n","    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=20, input_length=sequence_length),\n","    Bidirectional(LSTM(130)),\n","\n","    Dense(len(tokenizer.word_index)+1, activation='softmax')\n","])\n","\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X, y, epochs=50,batch_size=512)\n","\n","#save the model\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/gpt/LEVX/LEVXmodel1.keras\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[{"file_id":"1PKiCntrB2pBLVWZRaL6x-uJpEvPlNmAg","timestamp":1717661221746},{"file_id":"1qsxpGdTrTbO4obEJ4QwGeDJUpuX7gXoW","timestamp":1717492644174},{"file_id":"1LGw-aME2JOnpzAyMOVamYWUAywgSV5mI","timestamp":1715852482288},{"file_id":"1_9maObId68xlnKd6JjYqJUMRMI14ASnx","timestamp":1715845357828},{"file_id":"1BterrhINI5z4G_D4Ntuk7p8a0iuZu7ql","timestamp":1714808806688},{"file_id":"1sqdm_O_jJnvjiOLxkCsuGODjv7CDiB0l","timestamp":1714549345450},{"file_id":"1GD83k4KMSFWH42Th2LjdPwK-hN39h8RT","timestamp":1713425984380}],"mount_file_id":"17w5rjAKFoODXgDJDK2VRiudbvcVIRXUf","authorship_tag":"ABX9TyPjI/prCPVxmQhrAraJYj4S"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}